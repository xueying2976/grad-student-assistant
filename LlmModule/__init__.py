from .llmproxy import generate, pdf_upload
from random import randint
import requests, os
from bs4 import BeautifulSoup
from urllib.parse import quote

API_KEY = os.environ.get("GOOGLE_API_KEY")
CX = os.environ.get("GOOGLE_CX")

class LlmModule:
    def __init__(self):
        self.session_id = f'liuxueying-{randint(1000000000, 9999999999)}'
        self.create_context()
        print(f'New session created with ID: {self.session_id}')

    def create_context(self):
        response = pdf_upload(
            path='./context.pdf',
            session_id=self.session_id,
            strategy='smart'
        )
        print(f'Context created: {response}')

    def ask_question(self, question: str) -> str:
        """First, check if the query needs syllabus info. If not, use RAG directly."""
        
        # 1Ô∏è‚É£ ËÆ© ChatGPT Âà§Êñ≠ÊòØÂê¶ÈúÄË¶Å syllabus
        syllabus_check = generate(
            model="4o-mini",
            system="Determine whether the following query is directly asking for details about a specific course at Tufts University, "
                   "such as prerequisites, topics covered, grading policies, or required textbooks. "
                   "If the query is general (e.g., about AI, programming, or university policies) or not course-related, respond with 'no'. "
                   "Respond only with 'yes' or 'no'.",
            query=question,
            temperature=0,
            session_id=self.session_id,
            lastk=1024
        )
        
        if isinstance(syllabus_check, dict):
            syllabus_check = syllabus_check['response']

        print(f"DEBUG: Syllabus requirement check: {syllabus_check}")

        if syllabus_check.strip().lower() == "no":
            # 2Ô∏è‚É£ Â¶ÇÊûú‰∏çÈúÄË¶Å syllabusÔºåÁõ¥Êé•Áî® RAG
            response = generate(
                model="4o-mini",
                system="You are an AI assistant helping Tufts graduate students with course-related information. "
                       "If the user's question is too broad (e.g., 'What can you do?') or if the response lacks details, "
                       "provide a structured usage guide including:\n\n"
                       "üîπ **Who You Are:**\n"
                       "   - 'I am an AI assistant designed to help Tufts students with course-related queries, including syllabus details, prerequisites, grading policies, and course recommendations.'\n\n"
                       "üìå **How to Ask Questions:**\n"
                       "   - Be specific! Provide a course number (e.g., 'CS160').\n"
                       "   - Mention what details you need (e.g., grading, prerequisites, syllabus breakdown).\n\n"
                       "üéØ **Examples of Good Questions:**\n"
                       "   - ‚úÖ 'What are the prerequisites for CS160?'\n"
                       "   - ‚úÖ 'Can you show me the grading policy for CS160?'\n"
                       "   - ‚úÖ 'Which courses should I take if I'm interested in AI?'\n\n"
                       "üé® **Response Format & Style Guidelines:**\n"
                       "   - Use clear sections üìå to structure information.\n"
                       "   - Use bullet points ‚úÖ to organize content.\n"
                       "   - Include emojis ‚ú® to enhance readability.\n"
                       "   - Provide links üîó if available for further reading.\n\n"
                       "Please guide users to ask better questions and ensure responses are engaging and visually structured.",
                query=f"Question: {question}",
                temperature=0.3,
                lastk=1024,
                session_id=self.session_id,
                rag_usage=True,
                rag_threshold=0.4,
                rag_k=5
            )
            
            print(f"Final response (No syllabus needed): {response['response']}")
            return response["response"]

        # 3Ô∏è‚É£ ËÆ© ChatGPT ÈÄöËøá RAG ÊèêÂèñÊâÄÊúâÁõ∏ÂÖ≥ËØæÁ®ã
        course_list_check = generate(
            model="4o-mini",
            system="Extract only the official Tufts University course names and their corresponding course codes "
                   "strictly from the provided knowledge base. Do NOT create or assume course names. "
                   "Return them in a comma-separated format like: CS160:Machine Learning, CS105:Data Structures."
                   "Return at most 2 classes; you may return only one class if you think only one is relevant.",
            query=question,
            temperature=0,
            lastk=1024,
            session_id=self.session_id,
            rag_usage=True,  
            rag_threshold=0.4,
            rag_k=5
        )

        print(f'Course list: {course_list_check["response"]}')
        print(f"DEBUG: Full response from generate(): {course_list_check}")

        courses = [course.strip() for course in course_list_check["response"].split(",")]
        
        syllabus_content = ""
        reference = "\n\nReference:\n"

        # 4Ô∏è‚É£ ÈÅçÂéÜËØæÁ®ãÔºåGoogle ÊêúÁ¥¢ syllabus
        for course in courses:
            if ":" not in course:
                continue

            course_code, _, course_name = course.partition(":")  # ‚úÖ ‰øùÈöúËØæÁ®ãÂêçÁß∞ÂÆåÊï¥
            course_code = course_code.strip()
            course_name = course_name.strip()

            syllabus_url = self.search_syllabus(course_code, course_name)
            if syllabus_url:
                reference += f"- {syllabus_url} \n"
                syllabus_content += f"{course_code} - {course_name} Syllabus:\n"
                syllabus_content += self.scrape_syllabus(syllabus_url, 30000 // len(courses)) + "\n\n"

        print(f'Syllabus content: {syllabus_content}')
                
        # 5Ô∏è‚É£ LLM ÁªìÂêà RAG + syllabus ÁîüÊàêÊúÄÁªàÂõûÁ≠î
        response = generate(
            model="4o-mini",
            system="You are an AI assistant helping Tufts graduate students with course information. "
                   "Use the provided syllabus content if relevant. Never create courses that are not in the provided information. "
                   "If the question is too broad, ask for clarification.",
            query=f"Question: {question}\n\nSyllabus Content:\n{syllabus_content}",
            temperature=0.3,
            lastk=1024,
            session_id=self.session_id,
            rag_usage=True,  
            rag_threshold=0.4,
            rag_k=5
        )
        
        print(f'Final response: {response["response"]}')
        return response["response"] + (reference if reference[-2] != ':' else "")
    
    def receive_request(self, message: str) -> str:
        return self.ask_question(message)

    def search_syllabus(self, course_code, course_name):
        """Google Search for the first syllabus result"""
        query = f"Tufts {course_code} {course_name} syllabus"
        query = quote(query)
        url = f"https://www.googleapis.com/customsearch/v1?q={query}&key={API_KEY}&cx={CX}"

        response = requests.get(url)
        results = response.json()

        if "items" in results:
            return results["items"][0]["link"]
        return None
    
    def scrape_syllabus(self, url, length):
        """Scrape and extract relevant syllabus content from a webpage."""
        headers = {"User-Agent": "Mozilla/5.0"}
        response = requests.get(url, headers=headers)

        if response.status_code != 200:
            return "Unable to access syllabus page"

        soup = BeautifulSoup(response.text, "html.parser")

        # **1Ô∏è‚É£ Remove unnecessary elements like script, style, and footer**
        for tag in soup(["script", "style", "footer", "nav", "header", "aside"]):
            tag.decompose()  # Remove the tag completely

        # **2Ô∏è‚É£ Try to extract syllabus from common structures (table, sections, etc.)**
        syllabus_text = ""

        # Try extracting content from syllabus-specific sections
        syllabus_section = soup.find("section", class_="syllabus") or soup.find("div", class_="syllabus")
        if syllabus_section:
            syllabus_text = syllabus_section.get_text(separator="\n")

        # **3Ô∏è‚É£ If no structured syllabus section, extract from multiple text tags**
        if not syllabus_text.strip():
            paragraphs = soup.find_all(["p", "li", "div"])  # Grab multiple tag types
            syllabus_text = "\n".join(p.get_text() for p in paragraphs)

        # **4Ô∏è‚É£ Ensure the text is clean and readable**
        syllabus_text = syllabus_text.strip()
        
        return syllabus_text[:length]  # ‚úÖ Increase text limit for better results
    